{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "O6hDLd323-10",
        "outputId": "fb50aa1e-8cae-42d5-a182-a0d580d943b8"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/BrucceNeves/TSRN4HEN/archive/master.zip\n",
        "\n",
        "!unzip -q master.zip\n",
        "\n",
        "%cd TSRN4HEN-master/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random, json, numpy\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hO7ANF0U3h-U"
      },
      "source": [
        "## Creating a set with 50 labeled events for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "dtt8O6_sEJAE",
        "outputId": "82aef578-52e9-49b1-9541-be02b51f549b"
      },
      "outputs": [],
      "source": [
        "!cd labels && unzip inflation.zip\n",
        "!cd datasets && unzip inflation.zip\n",
        "\n",
        "list_labeled_events = 'labels/inflation.full_labels'\n",
        "output_labeled_events = 'labels/inflation.50_labeled_events'\n",
        "\n",
        "params_base = {}\n",
        "params_base['iterations'] = 1000\n",
        "params_base['convergenceThreshold'] = 0.00005\n",
        "params_base['relations'] = ['datasets/inflation.edges']\n",
        "params_base['labels'] = output_labeled_events\n",
        "\n",
        "# reading file with all labels\n",
        "labels = {}\n",
        "with open(list_labeled_events, 'r') as f:\n",
        "  for line in f:\n",
        "    node, label = line.strip().split('\\t')\n",
        "    if label not in labels:\n",
        "      labels[label] = []\n",
        "    labels[label].append(node)\n",
        "\n",
        "# selecting 50 random events of each class\n",
        "with open(output_labeled_events, 'w') as f:\n",
        "  for label in labels:\n",
        "    nodes = labels[label]\n",
        "    random.shuffle(nodes)\n",
        "    for i in range(50):\n",
        "      f.write(\"\\t\".join([nodes[i],label]) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnTeuDX8QxyR"
      },
      "source": [
        "# Running Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCdzZuJcNf63"
      },
      "source": [
        "Running HENR2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvcID16y6NGV"
      },
      "outputs": [],
      "source": [
        "data = params_base.copy()\n",
        "data['output_file'] = 'henr2.model'\n",
        "data['target_layer'] = 'event'\n",
        "data['mi'] = 1.0\n",
        "data['miBeta'] = 0.8\n",
        "\n",
        "with open('params.json', 'w') as outfile:\n",
        "  json.dump(data, outfile)\n",
        "\n",
        "# running algorithm\n",
        "!java -Xmx5G -cp TSRN4HEN.jar algorithms.HENR2 params.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvrVRA3GNlQM"
      },
      "source": [
        "Running GFHF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy5D5YXuNuZq"
      },
      "outputs": [],
      "source": [
        "data = params_base.copy()\n",
        "data['output_file'] = 'gfhf.model'\n",
        "\n",
        "with open('params.json', 'w') as outfile:\n",
        "  json.dump(data, outfile)\n",
        "\n",
        "!java -Xmx5G -cp TSRN4HEN.jar algorithms.GFHF params.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwq1ynAaQtVC"
      },
      "source": [
        "Running LPHN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7n6RqPHN3yn"
      },
      "outputs": [],
      "source": [
        "data = params_base.copy()\n",
        "data['output_file'] = 'lphn.model'\n",
        "\n",
        "with open('params.json', 'w') as outfile:\n",
        "  json.dump(data, outfile)\n",
        "\n",
        "!java -Xmx5G -cp TSRN4HEN.jar algorithms.LPHN params.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a4pHS7KOWm_"
      },
      "source": [
        "Running LLGC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "1GSU3DtKN96d",
        "outputId": "a5479aa6-d1a3-40a3-8ceb-d8f1eee72429"
      },
      "outputs": [],
      "source": [
        "data = params_base.copy()\n",
        "data['output_file'] = 'llgc.model'\n",
        "data['mi'] = 0.5\n",
        "\n",
        "with open('params.json', 'w') as outfile:\n",
        "  json.dump(data, outfile)\n",
        "\n",
        "!java -Xmx5G -cp TSRN4HEN.jar algorithms.LLGC params.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDUPw628OaBI"
      },
      "source": [
        "Running GNetMine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqzTs52GOdRH"
      },
      "outputs": [],
      "source": [
        "data = params_base.copy()\n",
        "data['output_file'] = 'gnetmine.model'\n",
        "data['mi'] = 0.5\n",
        "data['weight_relations'] = {}\n",
        "\n",
        "with open('params.json', 'w') as outfile:\n",
        "  json.dump(data, outfile)\n",
        "\n",
        "!java -Xmx5G -cp TSRN4HEN.jar algorithms.GNetMine params.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1r8nbnhOpXl"
      },
      "outputs": [],
      "source": [
        "data = params_base.copy()\n",
        "data['output_file'] = 'gnetmine.model'\n",
        "data['mi'] = 0.5\n",
        "data['weight_relations'] = {'event_temporal': 0.2, 'event_HL': 0.3, 'event_bag':0.7, 'event_geographic': 0.5}\n",
        "\n",
        "with open('params.json', 'w') as outfile:\n",
        "  json.dump(data, outfile)\n",
        "\n",
        "!java -Xmx5G -cp TSRN4HEN.jar algorithms.GNetMine params.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IKBgIBWQS-R"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny7eepaH38fM"
      },
      "source": [
        "Evaluation for HENR2, LLGC and GNetMine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "1zByrxwAQZp-",
        "outputId": "a3db70fa-2288-495b-e73f-525a30fa9ef0"
      },
      "outputs": [],
      "source": [
        "labeled_events = {}\n",
        "with open(list_labeled_events, 'r') as f:\n",
        "  for line in f:\n",
        "    node, label = line.strip().split('\\t')\n",
        "    label = numpy.argmax([float(x) for x in label.split(',')])\n",
        "    labeled_events[node] = label\n",
        "\n",
        "# remove labelled data\n",
        "with open(output_labeled_events, 'r') as f:\n",
        "  for line in f:\n",
        "    node, label = line.strip().split('\\t')\n",
        "    del labeled_events[node]\n",
        "\n",
        "output_model = 'gnetmine.model' # or 'llgc.model' or 'henr2.model'\n",
        "\n",
        "predicted = []\n",
        "real_label = []\n",
        "with open(output_model, 'r') as f:\n",
        "  for line in f:\n",
        "    node, label = line.strip().split('\\t')\n",
        "    if node not in labeled_events:\n",
        "      continue\n",
        "    label = numpy.argmax([float(x) for x in label.split(',')])\n",
        "    predicted.append(label)\n",
        "    real_label.append(labeled_events[node])\n",
        "\n",
        "print('macro', f1_score(real_label, predicted, average='macro'))\n",
        "print('micro', f1_score(real_label, predicted, average='micro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iXSJzFbYJNP"
      },
      "source": [
        "Evaluation for GFHF and LPHN\n",
        "\n",
        "Using Class Mass Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RwR-CmTYHN7"
      },
      "outputs": [],
      "source": [
        "labels_size = 0\n",
        "labeled_events = {}\n",
        "with open(list_labeled_events, 'r') as f:\n",
        "  for line in f:\n",
        "    node, label = line.strip().split('\\t')\n",
        "    label = numpy.argmax([float(x) for x in label.split(',')])\n",
        "    labeled_events[node] = {'real_label': label, 'predicted': -1}\n",
        "    if label > labels_size:\n",
        "      labels_size = label\n",
        "labels_size += 1\n",
        "\n",
        "# remove labelled data\n",
        "with open(output_labeled_events, 'r') as f:\n",
        "  for line in f:\n",
        "    node, label = line.strip().split('\\t')\n",
        "    del labeled_events[node]\n",
        "\n",
        "output_model = 'gfhf.model' # or 'lphn.model'\n",
        "\n",
        "cmn = numpy.zeros(labels_size)\n",
        "with open(output_model, 'r') as f:\n",
        "  for line in f:\n",
        "    node, label = line.strip().split('\\t')\n",
        "    if node not in labeled_events:\n",
        "      continue\n",
        "    label = numpy.array([float(x) for x in label.split(',')])\n",
        "    cmn += label\n",
        "    labeled_events[node]['predicted'] = label\n",
        "\n",
        "predicted = []\n",
        "real_label = []\n",
        "for node in labeled_events:\n",
        "  f = labeled_events[node]['predicted']\n",
        "  s = f.sum()\n",
        "  p = f/s\n",
        "  label = numpy.argmax(p * (f / cmn))\n",
        "  predicted.append(label)\n",
        "  real_label.append(labeled_events[node]['real_label'])\n",
        "\n",
        "print('macro', f1_score(real_label, predicted, average='macro'))\n",
        "print('micro', f1_score(real_label, predicted, average='micro'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
